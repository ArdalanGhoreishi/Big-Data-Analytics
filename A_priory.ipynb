{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuMnOOLYEqnr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7c2d3c7-8191-4aa0-d95a-0eaa42987c0e"
      },
      "source": [
        "!gdown --id 1o7B8XJ33OjCo8paZytvvVsxncm9wvVke"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1o7B8XJ33OjCo8paZytvvVsxncm9wvVke\n",
            "To: /content/BigData_Homework1_Data.zip\n",
            "377MB [00:05, 69.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB-TfqyEFFHC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "816ff542-3ee7-49e5-8f4c-3fa2aed70b70"
      },
      "source": [
        "!unzip BigData_Homework1_Data.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  BigData_Homework1_Data.zip\n",
            "   creating: Data/\n",
            "   creating: Data/question 2_Association rules' application/\n",
            "  inflating: Data/question 2_Association rules' application/browsing.txt  \n",
            "   creating: Data/question 3_LSH/\n",
            "   creating: Data/question 3_LSH/data/\n",
            "  inflating: Data/question 3_LSH/data/patches.csv  \n",
            "  inflating: Data/question 3_LSH/lsh.py  \n",
            "   creating: Data/question 4_Data streams/\n",
            "  inflating: Data/question 4_Data streams/counts.txt  \n",
            "  inflating: Data/question 4_Data streams/counts_tiny.txt  \n",
            "  inflating: Data/question 4_Data streams/hash_params.txt  \n",
            "  inflating: Data/question 4_Data streams/words_stream.txt  \n",
            "  inflating: Data/question 4_Data streams/words_stream_tiny.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz96shonFyfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a684f5f-b28d-4f73-a21e-8c975153d310"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 74kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 21.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=d2e09718805ed0165b55c147dcf6bfc2261a6c15dc4aeae23ec6872488e2caa1\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqCI_KMfZubr"
      },
      "source": [
        "please rename question 2 dataset folder to q2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYAhwnBqFZ0V"
      },
      "source": [
        "import operator\n",
        "from pyspark import SparkConf, SparkContext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYllzn1IFw63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a52828aa-c78e-4cbf-e0ae-970b8ad92f7d"
      },
      "source": [
        "sc = SparkContext(conf=SparkConf())\n",
        "\n",
        "lines = sc.textFile('/content/Data/q2/browsing.txt')\n",
        "baskets = lines.map(lambda l: l.split())\n",
        "N = baskets.count()\n",
        "\n",
        "baskets = baskets.map(lambda b: sorted(set(b)))\n",
        "\n",
        "# singles\n",
        "\n",
        "def singles_helper(basket):\n",
        "    temp = []\n",
        "    for item in basket:\n",
        "        temp.append((item, 1))\n",
        "    return temp\n",
        "\n",
        "\n",
        "singles_support = baskets.flatMap(singles_helper)\n",
        "singles_support = singles_support.reduceByKey(operator.add)\n",
        "singles_support = singles_support.filter(lambda x: x[1] >= 100)\n",
        "\n",
        "singles_support_b = {}\n",
        "for item, support in singles_support.collect():\n",
        "    singles_support_b[item] = support\n",
        "\n",
        "singles_support_b = sc.broadcast(singles_support_b)\n",
        "\n",
        "# doubles\n",
        "\n",
        "def doubles_helper(basket):\n",
        "    singles = singles_support_b.value\n",
        "    temp = []\n",
        "    for i in range(len(basket)):\n",
        "        if basket[i] in singles:\n",
        "            for j in range(i):\n",
        "                if basket[j] in singles:\n",
        "                    temp.append(((basket[j], basket[i]), 1)) # basket is sorted\n",
        "    return temp\n",
        "\n",
        "\n",
        "doubles_support = baskets.flatMap(doubles_helper)\n",
        "doubles_support = doubles_support.reduceByKey(operator.add)\n",
        "doubles_support = doubles_support.filter(lambda x: x[1] >= 100)\n",
        "\n",
        "def confidence_doubles_helper(double_support):\n",
        "    double, support = double_support\n",
        "    support = float(support)\n",
        "    u, v = double\n",
        "    singles = singles_support_b.value\n",
        "    uv_conf = support / singles[u]\n",
        "    vu_conf = support / singles[v]\n",
        "    return (('%s -> %s' % (u, v), uv_conf),\n",
        "            ('%s -> %s' % (v, u), vu_conf))\n",
        "\n",
        "\n",
        "doubles_conf = doubles_support.flatMap(confidence_doubles_helper)\n",
        "doubles_conf = doubles_conf.sortBy(lambda x: (-x[1], x[0]))\n",
        "\n",
        "doubles_support_b = {}\n",
        "for entry, support in doubles_support.collect():\n",
        "    doubles_support_b[entry] = support\n",
        "\n",
        "doubles_support_b = sc.broadcast(doubles_support_b)\n",
        "\n",
        "# triples\n",
        "\n",
        "def triples_helper(basket):\n",
        "    doubles = doubles_support_b.value\n",
        "    singles = singles_support_b.value\n",
        "    temp = []\n",
        "    for i in range(len(basket)):\n",
        "        if basket[i] not in singles:\n",
        "            continue\n",
        "        for j in range(i):\n",
        "            if basket[j] not in singles:\n",
        "                continue\n",
        "            if (basket[j], basket[i]) not in doubles:\n",
        "                continue\n",
        "            for k in range(j):\n",
        "                if basket[k] not in singles:\n",
        "                    continue\n",
        "                if (basket[k], basket[j]) not in doubles:\n",
        "                    continue\n",
        "                if (basket[k], basket[i]) not in doubles:\n",
        "                    continue\n",
        "                temp.append(((basket[k], basket[j], basket[i]), 1))\n",
        "    return temp\n",
        "\n",
        "\n",
        "triples_support = baskets.flatMap(triples_helper)\n",
        "triples_support = triples_support.reduceByKey(operator.add)\n",
        "triples_support = triples_support.filter(lambda x: x[1] >= 100)\n",
        "\n",
        "def confidence_triples_helper(triple_support):\n",
        "    doubles = doubles_support_b.value\n",
        "    triple, support = triple_support\n",
        "    support = float(support)\n",
        "    u, v, w = triple\n",
        "    uv_w = support / doubles[u, v]\n",
        "    uw_v = support / doubles[u, w]\n",
        "    vw_u = support / doubles[v, w]\n",
        "    return (('(%s, %s) -> %s' % (u, v, w), uv_w),\n",
        "            ('(%s, %s) -> %s' % (u, w, v), uw_v),\n",
        "            ('(%s, %s) -> %s' % (v, w, u), vw_u))\n",
        "\n",
        "\n",
        "triples_conf = triples_support.flatMap(confidence_triples_helper)\n",
        "triples_conf = triples_conf.sortBy(lambda x: (-x[1], x[0]))\n",
        "\n",
        "print(str(doubles_conf.take(5)))\n",
        "print('\\n')\n",
        "print(str(triples_conf.take(5)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('DAI93865 -> FRO40251', 1.0), ('GRO85051 -> FRO40251', 0.999176276771005), ('GRO38636 -> FRO40251', 0.9906542056074766), ('ELE12951 -> FRO40251', 0.9905660377358491), ('DAI88079 -> FRO40251', 0.9867256637168141)]\n",
            "\n",
            "\n",
            "[('(DAI23334, ELE92920) -> DAI62779', 1.0), ('(DAI31081, GRO85051) -> FRO40251', 1.0), ('(DAI55911, GRO85051) -> FRO40251', 1.0), ('(DAI62779, DAI88079) -> FRO40251', 1.0), ('(DAI75645, GRO85051) -> FRO40251', 1.0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FexMpnQVGuzh"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLD7GwclGvRi"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}